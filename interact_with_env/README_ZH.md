# Interact with Environment

<div align="left">
  <a href="README_ZH.md">ä¸­æ–‡</a> | <a href="README.md">English</a>
</div>

æœ¬é¡¹ç›®å®ç°Agentä¸Envçš„äº¤äº’ï¼Œä¸»è¦ç”¨äºï¼š
1. **ä¸EnvScaleråˆæˆç¯å¢ƒäº¤äº’**ï¼Œè·å–ç”¨äºè®­ç»ƒçš„æ•°æ®è½¨è¿¹
2. **è¯„ä¼°TauBenchå’ŒAceBenchç­‰åŸºå‡†æµ‹è¯•ç¯å¢ƒ**çš„æ€§èƒ½
3. **åœ¨RLè®­ç»ƒä¸­ä½œä¸ºéªŒè¯ç›‘æ§ç¯å¢ƒ**

<p align="center">
    <img src="../Figs/interact_with_env.png" width="30%"> <br>
  Diagram of <b>Agent-Env Interaction</b>.
</p>


## ğŸ“ ç›®å½•ç»“æ„

```
interact_with_env/
â”œâ”€â”€ run_main.py              # ä¸»ç¨‹åºï¼šæ‰¹é‡ä»»åŠ¡æ‰§è¡Œ
â”œâ”€â”€ run_main_debug.py        # è°ƒè¯•ç¨‹åºï¼šå•ä»»åŠ¡æ‰§è¡Œå’Œè°ƒè¯•
â”œâ”€â”€ traj_filter.py           # SFTé‡‡é›†è½¨è¿¹è¿‡æ»¤è„šæœ¬
â”œâ”€â”€ calc_avg_score.py        # è®¡ç®—å¹³å‡å¥–åŠ±åˆ†æ•°
â”œâ”€â”€ agent/                   # Agentæ¨¡å—
â”‚   â”œâ”€â”€ task_solve_agent.py      # LLM Agenté€»è¾‘å®ç°
â”‚   â”œâ”€â”€ agent_llm_inference.py   # LLMæ¨ç†æ¥å£
â”‚   â””â”€â”€ system_prompt_util.py    # Agentç³»ç»Ÿæç¤ºè¯
â”œâ”€â”€ envscaler_env/           # EnvScalerç¯å¢ƒï¼ˆè®­ç»ƒç”¨ï¼‰
â”œâ”€â”€ taubench_env/            # TauBenchç¯å¢ƒï¼ˆè¯„ä¼°ç”¨ï¼‰
â”œâ”€â”€ acebench_env/            # AceBench-Agentç¯å¢ƒï¼ˆè¯„ä¼°ç”¨ï¼‰
â”œâ”€â”€ bfcl_env/                # BFCL Multi-Turn-Baseç¯å¢ƒï¼ˆè®­ç»ƒç›‘æ§ç”¨ï¼‰
â”œâ”€â”€ result/                  # ç»“æœè¾“å‡ºç›®å½•
â””â”€â”€ result_debug/            # è°ƒè¯•ç»“æœç›®å½•
```

## ğŸ”„ Agentä¸Enväº¤äº’æµç¨‹

**Agentä¸ç¯å¢ƒçš„äº¤äº’éµå¾ªç±»ä¼¼[Gym](https://github.com/openai/gym)/[Gem](https://github.com/axon-rl/gem)çš„é£æ ¼**ï¼Œæ‚¨å¯ä»¥è½»æ¾çš„è¿ç§»ç¯å¢ƒåˆ°ç¬¦åˆGym/Gemé£æ ¼çš„è®­ç»ƒæ¡†æ¶ä¸Šã€‚
ä»¥ä¸‹æ˜¯æŠ½è±¡çš„äº¤äº’æµç¨‹ï¼š

```python
# é‡ç½®ç¯å¢ƒï¼Œè·å–Observation (ä»»åŠ¡ä¿¡æ¯æˆ–è€…ç”¨æˆ·å¯¹è¯)
observation, info = Env.reset(task_index=0)

max_step = 30
cur_step = 0
# äº¤äº’å¾ªç¯
while True:
    cur_step +=1
    # action: å·¥å…·è°ƒç”¨æˆ–è€…ä¸ç”¨æˆ·å¯¹è¯
    action = agent.step(observation)
    # observation: å·¥å…·æ‰§è¡Œç»“æœæˆ–è€…ç”¨æˆ·å›å¤
    observation, reward, terminated, truncated, info = Env.step(action)

    # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
    if terminated or truncated or cur_step > max_step: 
        break
```


æ‰§è¡Œä»»åŠ¡åï¼Œç»“æœä¼šä¿å­˜ä¸ºJSONæ–‡ä»¶ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{
    "task_info": {
        // ä»»åŠ¡ç›¸å…³ä¿¡æ¯ï¼ˆæ ¹æ®ç¯å¢ƒç±»å‹ä¸åŒè€Œä¸åŒï¼‰
    },
    "tools": [
        // å¯ç”¨å·¥å…·åˆ—è¡¨
    ],
    "messages": [
        // å®Œæ•´çš„å¯¹è¯å†å²
    ],
    "user_messages": [
        // ç”¨æˆ·æ¶ˆæ¯ï¼ˆä»…å¯¹è¯ç¯å¢ƒï¼‰
    ],
    "trajectory": [
        // æ¯ä¸€æ­¥çš„è¯¦ç»†ä¿¡æ¯
        {
            "step": 0,
            "observation": {...},
            "action": {...},
            "reward": 0.0,
            "terminated": false,
            "truncated": false
        }
    ],
    "total_reward": 0.0,
    "terminated": false,
    "truncated": false,
    "final_observation": {...},
    "final_info": {...},
    "steps": 10
}
```

## ğŸ”§ æ”¯æŒçš„ç¯å¢ƒ

### 1. EnvScalerè®­ç»ƒç¯å¢ƒ
```python
# EnvScaleréå¯¹è¯RLç¯å¢ƒ
env_name = "envscaler_non_conversation_rl"
env_config = {...}

# EnvScalerå¯¹è¯RLç¯å¢ƒ
env_name = "envscaler_conversation_rl"
env_config = {...}

# EnvScaleréå¯¹è¯SFTç¯å¢ƒ
env_name = "envscaler_non_conversation_sft"
env_config = {...}

# EnvScalerå¯¹è¯SFTç¯å¢ƒ
env_name = "envscaler_conversation_sft"
env_config = {...}
```
- æˆ‘ä»¬ä½¿ç”¨`envscaler_non_conversation_sft`ä¸`envscaler_non_conversation_sft`ç”¨äºSFTè®­ç»ƒè½¨è¿¹é‡‡é›†ã€‚
- æˆ‘ä»¬è¿ç§»`envscaler_non_conversation_rl`ä¸`envscaler_non_conversation_rl`åˆ°ROLLæ¡†æ¶ç”¨äºRLè®­ç»ƒã€‚

### 2. TauBenchè¯„ä¼°ç¯å¢ƒ
```python
# TauBenché›¶å”®ç¯å¢ƒ
env_name = "tau_bench_retail"
env_config = {...}

# TauBenchèˆªç©ºç¯å¢ƒ
env_name = "tau_bench_airline"
env_config = {...}
```
- æˆ‘ä»¬ä½¿ç”¨`tau_bench_retail`ä¸`tau_bench_airline`ç¯å¢ƒç”¨äºè®ºæ–‡ä¸­çš„å®éªŒè¯„ä¼°ã€‚
- æˆ‘ä»¬é‡æ–°ç¼–æ’[TauBench](https://github.com/sierra-research/tau-bench)çš„å®˜æ–¹ä»£ç , å¹¶å°½åŠ›ä¿ç•™åŸå§‹çš„å®ç°é€»è¾‘ã€‚


### 3. AceBench-Agentè¯„ä¼°ç¯å¢ƒ
```python
# AceBenchå¤šæ­¥éª¤ç¯å¢ƒ
env_name = "acebench_multi_step"
env_config = {...}

# AceBench-Agentè¯„ä¼°ç¯å¢ƒ
env_name = "acebench_multi_turn"
env_config = {...}
```
- æˆ‘ä»¬ä½¿ç”¨`acebench_multi_step`ä¸`acebench_multi_turn`ç¯å¢ƒç”¨äºè®ºæ–‡ä¸­çš„å®éªŒè¯„ä¼°ã€‚
- æˆ‘ä»¬é‡æ–°ç¼–æ’[AceBench](https://github.com/chenchen0103/ACEBench)çš„å®˜æ–¹ä»£ç , å¹¶å°½åŠ›ä¿ç•™åŸå§‹çš„å®ç°é€»è¾‘ã€‚
- å€¼å¾—æ³¨æ„çš„æ˜¯, ACEBench ä½¿ç”¨ `[func_name(param)]`promptæ ¼å¼; æˆ‘ä»¬ä¿®æ”¹äº†å®˜æ–¹ä»£ç ä»¥æ”¯æŒ LLM çš„åŸç”Ÿå‡½æ•°è°ƒç”¨æ¥å£ (FC)ï¼Œä»¥ç¡®ä¿ä¸€è‡´æ€§ã€‚

### 4. BFCLéªŒè¯ç¯å¢ƒ
```python
env_name = "bfcl"
env_config = {"mode": "multi_turn_base", ...}
```
- æˆ‘ä»¬ä½¿ç”¨`bfcl (multi_turn_base)`ç¯å¢ƒç”¨äºRLè®­ç»ƒè¿‡ç¨‹ä¸­çš„éªŒè¯ç›‘æ§ã€‚
- å¯¹äºè®ºæ–‡ä¸­çš„å®éªŒè¯„ä¼°ï¼Œæˆ‘ä»¬ä½¿ç”¨[BFCL](https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard)å®˜æ–¹çš„ä»£ç `(base, miss-param, miss-func, long-context)`ã€‚


## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# æ‰€æœ‰è„šæœ¬ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦ä» `interact_with_env` ç›®å½•è¿è¡Œ
cd interact_with_env
```

**è¿è¡Œä¸»ç¨‹åº:**

```bash
# ç”¨äºæ‰¹é‡å¤„ç†å¤šä¸ªä»»åŠ¡ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œ
python run_main.py
```
æ‚¨éœ€è¦åœ¨`run_main.py`ä¸­ä¿®æ”¹ä»¥ä¸‹é…ç½®ï¼š

```python
# 1. æ™ºèƒ½ä½“æ¨¡å‹é…ç½®
agent_model = "gpt-4.1"           # ä½¿ç”¨çš„æ¨¡å‹åç§°
agent_model_provider = "openai"        # æ¨¡å‹æä¾›å•†
enable_thinking = True                 # æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
num_workers = 3                        # å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°

# 2. ç¯å¢ƒé…ç½®
env_name = "selected_env_name"
infer_mode = "fc"                  # "prompt" æˆ– "fc"
env_config = {...} 
task_ids = [i for i in range(...)]   # ä»»åŠ¡IDåˆ—è¡¨
```

**Debugæ¨¡å¼:**
```bash
# ç”¨äºå•ä¸ªç¯å¢ƒä»»åŠ¡è°ƒè¯•ï¼š
python run_main_debug.py
```

---

## è®¸å¯è¯

æœ¬é¡¹ç›®å±äº EnvScaler é¡¹ç›®çš„ä¸€éƒ¨åˆ†ã€‚
